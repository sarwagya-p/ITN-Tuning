{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96781e81-0912-4f7d-a2ce-96c4c184059a",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@main#egg=nemo_toolkit[all]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "807827ca-168b-458b-8d98-1154372986ec",
   "metadata": {},
   "source": [
    "# Converting ChatGPT Text to tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154663cf-884e-4afc-b395-565b692b26f4",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "outData = pd.DataFrame(columns = [\"Written\", \"Spoken\"])\n",
    "\n",
    "with open(\"data/simple_text.txt\", \"r\") as inputFile:\n",
    "    line = inputFile.readline()\n",
    "\n",
    "    while line:\n",
    "        i = 0\n",
    "        while line[i] != \".\":\n",
    "            i+= 1\n",
    "        num = str(line[:i])\n",
    "\n",
    "        i += 8\n",
    "        written = line[i:len(line)-1]\n",
    "\n",
    "        line = inputFile.readline()\n",
    "        i=0\n",
    "        while line[i] != 'S':\n",
    "            i+= 1\n",
    "        i += 8\n",
    "        spoken = line[i:len(line)-1]\n",
    "\n",
    "        outData.loc[len(outData)] = {\"Written\": written, \"Spoken\": spoken}\n",
    "        inputFile.readline()\n",
    "        line = inputFile.readline()\n",
    "\n",
    "print(outData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3e34a76-702a-455a-b359-d45f3b05a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outData.to_csv(\"data/data.tsv\", mode='a', index=False, sep=\"\\t\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1df65990-a009-4730-80a6-b66d8c2f7130",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "833deb3f-74c4-48cc-aaef-1b5ac00978c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have five cats\n",
      "<class 'str'>\n",
      "the temperature is thirty degrees celsius\n",
      "<class 'str'>\n",
      "she arrived at nine forty-five a m\n",
      "<class 'str'>\n",
      "the book is two point five inches thick\n",
      "<class 'str'>\n",
      "the meeting starts at eight o'clock a m sharp\n",
      "<class 'str'>\n",
      "he finished the race in one hour twenty minutes\n",
      "<class 'str'>\n",
      "the package weighs two point three kilograms\n",
      "<class 'str'>\n",
      "the movie starts at seven thirty p m\n",
      "<class 'str'>\n",
      "the distance between the two cities is one hundred fifty miles\n",
      "<class 'str'>\n",
      "the shirt costs nineteen dollars and ninety-nine cent\n",
      "<class 'str'>\n",
      "['i have five cats', 'the temperature is thirty degrees celsius', 'she arrived at nine forty-five a m', 'the book is two point five inches thick', \"the meeting starts at eight o'clock a m sharp\", 'he finished the race in one hour twenty minutes', 'the package weighs two point three kilograms', 'the movie starts at seven thirty p m', 'the distance between the two cities is one hundred fifty miles', 'the shirt costs nineteen dollars and ninety-nine cent']\n"
     ]
    }
   ],
   "source": [
    "from nemo.collections.nlp.data.text_normalization_as_tagging.utils import spoken_preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/data.tsv\", sep=\"\\t\")\n",
    "\n",
    "# print(df['Spoken'])\n",
    "\n",
    "batch, all_preds = [], []\n",
    "for i, line in enumerate(df[\"Spoken\"]):\n",
    "    s = spoken_preprocessing(line)  # this is the same input transformation as in corpus preparation\n",
    "    batch.append(s.strip())\n",
    "    print(s)\n",
    "    print(type(s))\n",
    "\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeaaacc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-26 19:47:42 cloud:68] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/itn_en_thutmose_bert/versions/1.9.0/files/itn_en_thutmose_bert.nemo to /home/sarwagya/.cache/torch/NeMo/NeMo_1.19.0rc0/itn_en_thutmose_bert/bf3a085f3b78525c3b3abe09bd0c62c8/itn_en_thutmose_bert.nemo\n",
      "[NeMo I 2023-06-26 19:48:44 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2023-06-26 19:48:54 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-base-uncased, vocab_file: /tmp/tmpsonnv61w/1742bd18a2874ba6b6cb1d643dabcb2b_vocab.txt, merges_files: None, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n",
      "[NeMo W 2023-06-26 19:48:57 modelPT:244] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "[NeMo W 2023-06-26 19:48:57 nlp_overrides:249] Apex was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/apex\n",
      "    Megatron-based models require Apex to function correctly.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertEncoder: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-26 19:50:04 save_restore_connector:249] Model ThutmoseTaggerModel was successfully restored from /home/sarwagya/.cache/torch/NeMo/NeMo_1.19.0rc0/itn_en_thutmose_bert/bf3a085f3b78525c3b3abe09bd0c62c8/itn_en_thutmose_bert.nemo.\n",
      "['i have five cats\\ti have five cats\\t<SELF> <SELF> <SELF> <SELF>\\t<SELF> <SELF> <SELF> <SELF>\\tPLAIN PLAIN PLAIN PLAIN', 'the temperature is 30 degrees celsius\\tthe temperature is thirty degrees celsius\\t<SELF> <SELF> <SELF> _30_ <SELF> <SELF>\\t<SELF> <SELF> <SELF> _30_ <SELF> <SELF>\\tPLAIN PLAIN PLAIN CARDINAL PLAIN PLAIN', 'she arrived at 09:40 am\\tshe arrived at nine forty-five a m\\t<SELF> <SELF> <SELF> _09: 40_ _am_ <DELETE>\\t<SELF> <SELF> <SELF> _09: 40_ _am_ <DELETE>\\tPLAIN PLAIN PLAIN TIME TIME TIME TIME', 'the book is 2.5 inches thick\\tthe book is two point five inches thick\\t<SELF> <SELF> <SELF> _2 . 5_ <SELF> <SELF>\\t<SELF> <SELF> <SELF> _2 . 5_ <SELF> <SELF>\\tPLAIN PLAIN PLAIN DECIMAL DECIMAL DECIMAL PLAIN PLAIN', \"the meeting starts at 8:00 08:00 a m sharp\\tthe meeting starts at eight o'clock a m sharp\\t<SELF> <SELF> <SELF> <SELF> _8:00_ _08:00_ <SELF> <SELF> <SELF>\\t<SELF> <SELF> <SELF> <SELF> _8:00_ _08:00_ <SELF> <SELF> <SELF>\\tPLAIN PLAIN PLAIN PLAIN TIME TIME PLAIN PLAIN PLAIN\", 'he finished the race in 1 hour 20 minutes\\the finished the race in one hour twenty minutes\\t<SELF> <SELF> <SELF> <SELF> <SELF> _1_ <SELF> _20_ <SELF>\\t<SELF> <SELF> <SELF> <SELF> <SELF> _1_ <SELF> _20_ <SELF>\\tPLAIN PLAIN PLAIN PLAIN PLAIN MEASURE MEASURE CARDINAL PLAIN', 'the package weighs 2.3 kg\\tthe package weighs two point three kilograms\\t<SELF> <SELF> <SELF> _2 . 3_ _kg_\\t<SELF> <SELF> <SELF> _2 . 3_ _kg_\\tPLAIN PLAIN PLAIN MEASURE MEASURE MEASURE MEASURE', 'the movie starts at 7:30 pm\\tthe movie starts at seven thirty p m\\t<SELF> <SELF> <SELF> <SELF> _7: 30_ _pm_ <DELETE>\\t<SELF> <SELF> <SELF> <SELF> _7: 30_ _pm_ <DELETE>\\tPLAIN PLAIN PLAIN PLAIN TIME TIME TIME TIME', 'the distance between the two cities is 150 miles\\tthe distance between the two cities is one hundred fifty miles\\t<SELF> <SELF> <SELF> <SELF> <SELF> <SELF> <SELF> _1 <DELETE> 50_ <SELF>\\t<SELF> <SELF> <SELF> <SELF> <SELF> <SELF> <SELF> _1 <DELETE> 50_ <SELF>\\tPLAIN PLAIN PLAIN PLAIN PLAIN PLAIN PLAIN CARDINAL CARDINAL CARDINAL PLAIN', 'the shirt costs 1 9. 9 cent\\tthe shirt costs nineteen dollars and ninety-nine cent\\t<SELF> <SELF> <SELF> _1 <DELETE> 9. 9 <SELF>\\t<SELF> <SELF> <SELF> _1 <DELETE> 9. 9 <SELF>\\tPLAIN PLAIN PLAIN MONEY MONEY MONEY MONEY MONEY']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from nemo.collections import nlp as nemo_nlp\n",
    "\n",
    "thutmose = nemo_nlp.models.ThutmoseTaggerModel.from_pretrained(\"itn_en_thutmose_bert\")\n",
    "\n",
    "outputs = thutmose._infer(batch)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75558772",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/pretrained_nemo_output.tsv\", \"w\") as file:\n",
    "    for line in outputs:\n",
    "        file.write(line)\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b297c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
